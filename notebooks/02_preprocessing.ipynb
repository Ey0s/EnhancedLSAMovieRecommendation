{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced Movie Data Preprocessing for LSA Recommendation System\n",
    "## Advanced preprocessing with weighted features and comprehensive text engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Movie Data Preprocessing\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download required NLTK data\n",
    "try:\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "except:\n",
    "    print(\"NLTK data already downloaded or download failed\")\n",
    "\n",
    "print(\"Enhanced Movie Data Preprocessing\")\n",
    "print(\"================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded processed dataset: (2723, 32)\n",
      "\n",
      "Dataset Overview:\n",
      "   Movies: 2723\n",
      "   Features: 32\n",
      "   Memory usage: 30.2 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_title</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>...</th>\n",
       "      <th>title</th>\n",
       "      <th>genres_list</th>\n",
       "      <th>num_genres</th>\n",
       "      <th>cast_list</th>\n",
       "      <th>num_cast</th>\n",
       "      <th>director</th>\n",
       "      <th>overview_length</th>\n",
       "      <th>overview_word_count</th>\n",
       "      <th>release_year</th>\n",
       "      <th>release_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Avatar</td>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>...</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>['Action', 'Adventure', 'Fantasy', 'Science Fi...</td>\n",
       "      <td>4</td>\n",
       "      <td>['Sam Worthington', 'Zoe Saldana', 'Sigourney ...</td>\n",
       "      <td>5</td>\n",
       "      <td>James Cameron</td>\n",
       "      <td>175</td>\n",
       "      <td>28</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spectre</td>\n",
       "      <td>245000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spectre/</td>\n",
       "      <td>206647</td>\n",
       "      <td>[{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...</td>\n",
       "      <td>en</td>\n",
       "      <td>A cryptic message from Bond’s past sends him o...</td>\n",
       "      <td>107.376788</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>...</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>['Action', 'Adventure', 'Crime']</td>\n",
       "      <td>3</td>\n",
       "      <td>['Daniel Craig', 'Christoph Waltz', 'Léa Seydo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sam Mendes</td>\n",
       "      <td>240</td>\n",
       "      <td>41</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>250000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...</td>\n",
       "      <td>http://www.thedarkknightrises.com/</td>\n",
       "      <td>49026</td>\n",
       "      <td>[{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...</td>\n",
       "      <td>en</td>\n",
       "      <td>Following the death of District Attorney Harve...</td>\n",
       "      <td>112.312950</td>\n",
       "      <td>[{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>['Action', 'Crime', 'Drama', 'Thriller']</td>\n",
       "      <td>4</td>\n",
       "      <td>['Christian Bale', 'Michael Caine', 'Gary Oldm...</td>\n",
       "      <td>5</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>428</td>\n",
       "      <td>65</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Carter</td>\n",
       "      <td>260000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://movies.disney.com/john-carter</td>\n",
       "      <td>49529</td>\n",
       "      <td>[{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>John Carter is a war-weary, former military ca...</td>\n",
       "      <td>43.926995</td>\n",
       "      <td>[{\"name\": \"Walt Disney Pictures\", \"id\": 2}]</td>\n",
       "      <td>...</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>['Action', 'Adventure', 'Science Fiction']</td>\n",
       "      <td>3</td>\n",
       "      <td>['Taylor Kitsch', 'Lynn Collins', 'Samantha Mo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Andrew Stanton</td>\n",
       "      <td>342</td>\n",
       "      <td>55</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>258000000</td>\n",
       "      <td>[{\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 28, \"na...</td>\n",
       "      <td>http://www.sonypictures.com/movies/spider-man3/</td>\n",
       "      <td>559</td>\n",
       "      <td>[{\"id\": 851, \"name\": \"dual identity\"}, {\"id\": ...</td>\n",
       "      <td>en</td>\n",
       "      <td>The seemingly invincible Spider-Man goes up ag...</td>\n",
       "      <td>115.699814</td>\n",
       "      <td>[{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...</td>\n",
       "      <td>...</td>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>['Fantasy', 'Action', 'Adventure']</td>\n",
       "      <td>3</td>\n",
       "      <td>['Tobey Maguire', 'Kirsten Dunst', 'James Fran...</td>\n",
       "      <td>5</td>\n",
       "      <td>Sam Raimi</td>\n",
       "      <td>287</td>\n",
       "      <td>45</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          original_title     budget  \\\n",
       "0                 Avatar  237000000   \n",
       "1                Spectre  245000000   \n",
       "2  The Dark Knight Rises  250000000   \n",
       "3            John Carter  260000000   \n",
       "4           Spider-Man 3  258000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "1  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "2  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 80, \"nam...   \n",
       "3  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "4  [{\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 28, \"na...   \n",
       "\n",
       "                                          homepage      id  \\\n",
       "0                      http://www.avatarmovie.com/   19995   \n",
       "1      http://www.sonypictures.com/movies/spectre/  206647   \n",
       "2               http://www.thedarkknightrises.com/   49026   \n",
       "3             http://movies.disney.com/john-carter   49529   \n",
       "4  http://www.sonypictures.com/movies/spider-man3/     559   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "1  [{\"id\": 470, \"name\": \"spy\"}, {\"id\": 818, \"name...                en   \n",
       "2  [{\"id\": 849, \"name\": \"dc comics\"}, {\"id\": 853,...                en   \n",
       "3  [{\"id\": 818, \"name\": \"based on novel\"}, {\"id\":...                en   \n",
       "4  [{\"id\": 851, \"name\": \"dual identity\"}, {\"id\": ...                en   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "1  A cryptic message from Bond’s past sends him o...  107.376788   \n",
       "2  Following the death of District Attorney Harve...  112.312950   \n",
       "3  John Carter is a war-weary, former military ca...   43.926995   \n",
       "4  The seemingly invincible Spider-Man goes up ag...  115.699814   \n",
       "\n",
       "                                production_companies  ...  \\\n",
       "0  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...  ...   \n",
       "1  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...  ...   \n",
       "2  [{\"name\": \"Legendary Pictures\", \"id\": 923}, {\"...  ...   \n",
       "3        [{\"name\": \"Walt Disney Pictures\", \"id\": 2}]  ...   \n",
       "4  [{\"name\": \"Columbia Pictures\", \"id\": 5}, {\"nam...  ...   \n",
       "\n",
       "                   title                                        genres_list  \\\n",
       "0                 Avatar  ['Action', 'Adventure', 'Fantasy', 'Science Fi...   \n",
       "1                Spectre                   ['Action', 'Adventure', 'Crime']   \n",
       "2  The Dark Knight Rises           ['Action', 'Crime', 'Drama', 'Thriller']   \n",
       "3            John Carter         ['Action', 'Adventure', 'Science Fiction']   \n",
       "4           Spider-Man 3                 ['Fantasy', 'Action', 'Adventure']   \n",
       "\n",
       "   num_genres                                          cast_list num_cast  \\\n",
       "0           4  ['Sam Worthington', 'Zoe Saldana', 'Sigourney ...        5   \n",
       "1           3  ['Daniel Craig', 'Christoph Waltz', 'Léa Seydo...        5   \n",
       "2           4  ['Christian Bale', 'Michael Caine', 'Gary Oldm...        5   \n",
       "3           3  ['Taylor Kitsch', 'Lynn Collins', 'Samantha Mo...        5   \n",
       "4           3  ['Tobey Maguire', 'Kirsten Dunst', 'James Fran...        5   \n",
       "\n",
       "            director overview_length  overview_word_count  release_year  \\\n",
       "0      James Cameron             175                   28        2009.0   \n",
       "1         Sam Mendes             240                   41        2015.0   \n",
       "2  Christopher Nolan             428                   65        2012.0   \n",
       "3     Andrew Stanton             342                   55        2012.0   \n",
       "4          Sam Raimi             287                   45        2007.0   \n",
       "\n",
       "   release_month  \n",
       "0           12.0  \n",
       "1           10.0  \n",
       "2            7.0  \n",
       "3            3.0  \n",
       "4            5.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the raw dataset\n",
    "try:\n",
    "    df = pd.read_csv(\"../data/processed/movies_with_features.csv\")\n",
    "    print(f\"Loaded processed dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    # If processed file doesn't exist, load and merge raw files\n",
    "    print(\" Loading raw datasets...\")\n",
    "    movies = pd.read_csv(\"../data/raw/tmdb_5000_movies.csv\")\n",
    "    credits = pd.read_csv(\"../data/raw/tmdb_5000_credits.csv\")\n",
    "    \n",
    "    # Merge datasets\n",
    "    df = movies.merge(credits, left_on='id', right_on='movie_id', how='inner')\n",
    "    print(f\"Merged raw datasets: {df.shape}\")\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"   Movies: {len(df)}\")\n",
    "print(f\"   Features: {len(df.columns)}\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "\n",
    "# Display basic info\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Enhanced Data Cleaning and Missing Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Analysis:\n",
      "          column  missing_count  missing_percentage    dtype\n",
      "0       homepage           3091           64.369013   object\n",
      "4        tagline            844           17.576010   object\n",
      "5       director             30            0.624740   object\n",
      "1       overview              3            0.062474   object\n",
      "3        runtime              2            0.041649  float64\n",
      "2   release_date              1            0.020825   object\n",
      "6   release_year              1            0.020825  float64\n",
      "7  release_month              1            0.020825  float64\n",
      "\n",
      "Enhanced Missing Value Handling:\n",
      "overview: filled 3 missing values with empty string\n",
      "tagline: filled 844 missing values with empty string\n",
      "homepage: filled 3091 missing values with empty string\n",
      "runtime: filled 2 missing values with 106.86\n",
      "genres: processed 4802 JSON lists\n",
      "keywords: processed 4802 JSON lists\n",
      "cast: processed 4802 JSON lists\n",
      "crew: processed 4802 JSON lists\n",
      "production_companies: processed 4802 JSON lists\n",
      "production_countries: processed 4802 JSON lists\n",
      "spoken_languages: processed 4802 JSON lists\n"
     ]
    }
   ],
   "source": [
    "# Advanced missing value analysis\n",
    "def analyze_missing_values(df):\n",
    "    \"\"\"\n",
    "    Comprehensive missing value analysis\n",
    "    \"\"\"\n",
    "    missing_info = []\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        missing_pct = (missing_count / len(df)) * 100\n",
    "        if missing_count > 0:\n",
    "            missing_info.append({\n",
    "                'column': col,\n",
    "                'missing_count': missing_count,\n",
    "                'missing_percentage': missing_pct,\n",
    "                'dtype': str(df[col].dtype)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(missing_info).sort_values(\n",
    "        'missing_percentage', ascending=False\n",
    "    )\n",
    "\n",
    "print(\"Missing Value Analysis:\")\n",
    "missing_analysis = analyze_missing_values(df)\n",
    "if not missing_analysis.empty:\n",
    "    print(missing_analysis.head(10))\n",
    "else:\n",
    "    print(\"No missing values found.\")\n",
    "\n",
    "# Enhanced missing value handling\n",
    "print(\"\\nEnhanced Missing Value Handling:\")\n",
    "\n",
    "# Text columns → fill with empty string\n",
    "text_cols = ['overview', 'tagline', 'homepage']\n",
    "for col in text_cols:\n",
    "    if col in df.columns:\n",
    "        before_count = df[col].isnull().sum()\n",
    "        df[col] = df[col].fillna('')\n",
    "        print(f\"{col}: filled {before_count} missing values with empty string\")\n",
    "\n",
    "# Numeric columns → intelligent filling\n",
    "numeric_cols = [\n",
    "    'budget', 'popularity', 'revenue',\n",
    "    'runtime', 'vote_average', 'vote_count'\n",
    "]\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        before_count = df[col].isnull().sum()\n",
    "        if before_count > 0:\n",
    "            if col in ['budget', 'revenue', 'popularity']:\n",
    "                fill_value = df[col].median()\n",
    "            else:\n",
    "                fill_value = df[col].mean()\n",
    "\n",
    "            df[col] = df[col].fillna(fill_value)\n",
    "            print(\n",
    "                f\"{col}: filled {before_count} missing values \"\n",
    "                f\"with {fill_value:.2f}\"\n",
    "            )\n",
    "\n",
    "# List columns → convert from string JSON to list\n",
    "list_cols = [\n",
    "    'genres', 'keywords', 'cast', 'crew',\n",
    "    'production_companies', 'production_countries',\n",
    "    'spoken_languages'\n",
    "]\n",
    "for col in list_cols:\n",
    "    if col in df.columns:\n",
    "        before_count = df[col].isnull().sum()\n",
    "        df[col] = df[col].apply(\n",
    "            lambda x: [] if pd.isna(x) or x == '[]'\n",
    "            else ast.literal_eval(x) if isinstance(x, str)\n",
    "            else x\n",
    "        )\n",
    "        print(f\"{col}: processed {len(df) - before_count} JSON lists\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Feature Extraction:\n",
      "   Genres extracted: 7520 total\n",
      "   Keywords extracted: 22389 total\n",
      "   Cast members extracted: 37932 total\n",
      "   Directors extracted: 2920 total\n",
      "   Key crew extracted: 10155 total\n"
     ]
    }
   ],
   "source": [
    "# Enhanced feature extraction with better error handling\n",
    "def extract_names_advanced(obj_list, key='name', top_n=None, fallback_key=None):\n",
    "    \"\"\"\n",
    "    Advanced name extraction with fallback options\n",
    "    \"\"\"\n",
    "    if not obj_list or not isinstance(obj_list, list):\n",
    "        return []\n",
    "    \n",
    "    names = []\n",
    "    for obj in obj_list:\n",
    "        if isinstance(obj, dict):\n",
    "            if key in obj and obj[key]:\n",
    "                names.append(str(obj[key]).strip())\n",
    "            elif fallback_key and fallback_key in obj and obj[fallback_key]:\n",
    "                names.append(str(obj[fallback_key]).strip())\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    seen = set()\n",
    "    unique_names = []\n",
    "    for name in names:\n",
    "        if name.lower() not in seen:\n",
    "            seen.add(name.lower())\n",
    "            unique_names.append(name)\n",
    "    \n",
    "    if top_n:\n",
    "        return unique_names[:top_n]\n",
    "    return unique_names\n",
    "\n",
    "print(\"Advanced Feature Extraction:\")\n",
    "\n",
    "# Extract enhanced features\n",
    "df['genres_list'] = df['genres'].apply(lambda x: extract_names_advanced(x))\n",
    "df['keywords_list'] = df['keywords'].apply(lambda x: extract_names_advanced(x, top_n=20))  # Limit keywords\n",
    "df['cast_list'] = df['cast'].apply(lambda x: extract_names_advanced(x, top_n=15))  # Top 15 cast\n",
    "df['director_list'] = df['crew'].apply(lambda x: [d['name'] for d in x if isinstance(d, dict) and d.get('job')=='Director'] if x else [])\n",
    "df['companies_list'] = df['production_companies'].apply(lambda x: extract_names_advanced(x, top_n=5))\n",
    "df['countries_list'] = df['production_countries'].apply(lambda x: extract_names_advanced(x))\n",
    "df['languages_list'] = df['spoken_languages'].apply(lambda x: extract_names_advanced(x, key='name'))\n",
    "\n",
    "# Extract additional crew roles for better recommendations\n",
    "def extract_crew_roles(crew_list, roles=['Producer', 'Writer', 'Screenplay', 'Cinematography']):\n",
    "    \"\"\"\n",
    "    Extract specific crew roles\n",
    "    \"\"\"\n",
    "    if not crew_list:\n",
    "        return []\n",
    "    \n",
    "    crew_names = []\n",
    "    for person in crew_list:\n",
    "        if isinstance(person, dict) and person.get('job') in roles:\n",
    "            crew_names.append(person.get('name', ''))\n",
    "    \n",
    "    return crew_names[:5]  # Limit to top 5\n",
    "\n",
    "df['key_crew_list'] = df['crew'].apply(extract_crew_roles)\n",
    "\n",
    "print(f\"   Genres extracted: {df['genres_list'].apply(len).sum()} total\")\n",
    "print(f\"   Keywords extracted: {df['keywords_list'].apply(len).sum()} total\")\n",
    "print(f\"   Cast members extracted: {df['cast_list'].apply(len).sum()} total\")\n",
    "print(f\"   Directors extracted: {df['director_list'].apply(len).sum()} total\")\n",
    "print(f\"   Key crew extracted: {df['key_crew_list'].apply(len).sum()} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Enhanced Numerical Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced Numerical Feature Engineering:\n",
      "   Temporal features created from release_date\n",
      "   Financial features created\n",
      "   Rating and popularity features created\n",
      "\n",
      "Feature Summary:\n",
      "   Total features: 52\n",
      "   Numerical features: 28\n",
      "   Text features: 23\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive numerical features\n",
    "print(\"Enhanced Numerical Feature Engineering:\")\n",
    "\n",
    "# Count features\n",
    "df['num_genres'] = df['genres_list'].apply(len)\n",
    "df['num_keywords'] = df['keywords_list'].apply(len)\n",
    "df['num_cast'] = df['cast_list'].apply(len)\n",
    "df['num_directors'] = df['director_list'].apply(len)\n",
    "df['num_companies'] = df['companies_list'].apply(len)\n",
    "df['num_countries'] = df['countries_list'].apply(len)\n",
    "df['num_languages'] = df['languages_list'].apply(len)\n",
    "df['num_key_crew'] = df['key_crew_list'].apply(len)\n",
    "\n",
    "# Text-based features\n",
    "df['overview_length'] = df['overview'].apply(lambda x: len(str(x)))\n",
    "df['overview_word_count'] = df['overview'].apply(lambda x: len(str(x).split()))\n",
    "df['title_length'] = df['original_title'].apply(lambda x: len(str(x)))\n",
    "\n",
    "# Temporal features\n",
    "if 'release_date' in df.columns:\n",
    "    df['release_date'] = pd.to_datetime(df['release_date'], errors='coerce')\n",
    "    df['release_year'] = df['release_date'].dt.year\n",
    "    df['release_month'] = df['release_date'].dt.month\n",
    "    df['release_day_of_year'] = df['release_date'].dt.dayofyear\n",
    "    \n",
    "    # Create decade feature\n",
    "    df['release_decade'] = (df['release_year'] // 10) * 10\n",
    "    \n",
    "    print(f\"   Temporal features created from release_date\")\n",
    "\n",
    "# Financial ratios and derived features\n",
    "if 'budget' in df.columns and 'revenue' in df.columns:\n",
    "    df['profit'] = df['revenue'] - df['budget']\n",
    "    df['roi'] = np.where(df['budget'] > 0, df['profit'] / df['budget'], 0)\n",
    "    df['budget_per_minute'] = np.where(df['runtime'] > 0, df['budget'] / df['runtime'], 0)\n",
    "    \n",
    "    print(f\"   Financial features created\")\n",
    "\n",
    "# Rating and popularity features\n",
    "if 'vote_average' in df.columns and 'vote_count' in df.columns:\n",
    "    # Weighted rating (IMDB formula)\n",
    "    C = df['vote_average'].mean()  # Mean vote across all movies\n",
    "    m = df['vote_count'].quantile(0.9)  # Minimum votes required\n",
    "    df['weighted_rating'] = ((df['vote_count'] / (df['vote_count'] + m)) * df['vote_average'] + \n",
    "                            (m / (df['vote_count'] + m)) * C)\n",
    "    \n",
    "    # Popularity score combining rating and vote count\n",
    "    df['popularity_score'] = df['vote_average'] * np.log1p(df['vote_count'])\n",
    "    \n",
    "    print(f\"   Rating and popularity features created\")\n",
    "\n",
    "print(f\"\\nFeature Summary:\")\n",
    "print(f\"   Total features: {len(df.columns)}\")\n",
    "print(f\"   Numerical features: {len(df.select_dtypes(include=[np.number]).columns)}\")\n",
    "print(f\"   Text features: {len(df.select_dtypes(include=['object']).columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Text Preprocessing:\n",
      "   Creating text feature combinations...\n",
      "   Applying advanced text cleaning...\n",
      "   Text preprocessing complete\n",
      "   Average text feature length: 804 characters\n",
      "   Average word count: 112 words\n"
     ]
    }
   ],
   "source": [
    "# Advanced text preprocessing for LSA\n",
    "print(\"Advanced Text Preprocessing:\")\n",
    "\n",
    "# Enhanced stopwords\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    # Add movie-specific stopwords\n",
    "    movie_stopwords = {'movie', 'film', 'story', 'man', 'woman', 'one', 'two', 'get', 'go', 'come', 'see', 'know', 'time', 'way', 'make', 'take', 'find'}\n",
    "    stop_words.update(movie_stopwords)\n",
    "except:\n",
    "    stop_words = set()\n",
    "    print(\"   NLTK stopwords not available, using basic set\")\n",
    "\n",
    "# Initialize lemmatizer\n",
    "try:\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "except:\n",
    "    lemmatizer = None\n",
    "    print(\"   NLTK lemmatizer not available\")\n",
    "\n",
    "def advanced_text_cleaning(text):\n",
    "    \"\"\"\n",
    "    Advanced text cleaning for movie recommendation\n",
    "    \"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return ''\n",
    "    \n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove special characters but keep spaces\n",
    "    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Split into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Filter and lemmatize\n",
    "    processed_words = []\n",
    "    for word in words:\n",
    "        # Skip short words and stopwords\n",
    "        if len(word) < 2 or word in stop_words:\n",
    "            continue\n",
    "        \n",
    "        # Lemmatize if available\n",
    "        if lemmatizer:\n",
    "            word = lemmatizer.lemmatize(word)\n",
    "        \n",
    "        processed_words.append(word)\n",
    "    \n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "# Create multiple text feature combinations for LSA\n",
    "print(\"   Creating text feature combinations...\")\n",
    "\n",
    "# Standard text features (for comparison)\n",
    "df['text_features'] = (\n",
    "    df['overview'] + ' ' +\n",
    "    df['tagline'] + ' ' +\n",
    "    df['genres_list'].apply(lambda x: ' '.join(x)) + ' ' +\n",
    "    df['keywords_list'].apply(lambda x: ' '.join(x)) + ' ' +\n",
    "    df['cast_list'].apply(lambda x: ' '.join(x)) + ' ' +\n",
    "    df['director_list'].apply(lambda x: ' '.join(x))\n",
    ")\n",
    "\n",
    "# Enhanced weighted text features for better LSA performance\n",
    "df['enhanced_text_features'] = (\n",
    "    df['overview'] + ' ' +\n",
    "    df['tagline'] + ' ' +\n",
    "    # Weight genres heavily (4x) - most important for similarity\n",
    "    df['genres_list'].apply(lambda x: ' '.join(x * 4)) + ' ' +\n",
    "    # Weight keywords moderately (3x) - important for content similarity\n",
    "    df['keywords_list'].apply(lambda x: ' '.join(x * 3)) + ' ' +\n",
    "    # Weight directors heavily (3x) - important for style similarity\n",
    "    df['director_list'].apply(lambda x: ' '.join(x * 3)) + ' ' +\n",
    "    # Weight main cast moderately (2x)\n",
    "    df['cast_list'].apply(lambda x: ' '.join(x[:5] * 2)) + ' ' +\n",
    "    # Add key crew for additional context\n",
    "    df['key_crew_list'].apply(lambda x: ' '.join(x)) + ' ' +\n",
    "    # Add production companies for studio similarity\n",
    "    df['companies_list'].apply(lambda x: ' '.join(x))\n",
    ")\n",
    "\n",
    "# Apply advanced cleaning\n",
    "print(\"   Applying advanced text cleaning...\")\n",
    "df['text_features'] = df['text_features'].apply(advanced_text_cleaning)\n",
    "df['enhanced_text_features'] = df['enhanced_text_features'].apply(advanced_text_cleaning)\n",
    "\n",
    "# Create genre-specific text features\n",
    "df['genre_text'] = df['genres_list'].apply(lambda x: ' '.join(x * 5))  # Heavy genre weighting\n",
    "df['genre_text'] = df['genre_text'].apply(advanced_text_cleaning)\n",
    "\n",
    "print(f\"   Text preprocessing complete\")\n",
    "print(f\"   Average text feature length: {df['enhanced_text_features'].apply(len).mean():.0f} characters\")\n",
    "print(f\"   Average word count: {df['enhanced_text_features'].apply(lambda x: len(x.split())).mean():.0f} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Numerical Feature Scaling and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced Numerical Feature Processing:\n",
      "   Applying log transformation to skewed features: ['budget', 'revenue', 'popularity', 'runtime', 'vote_count']\n",
      "   Standardizing numerical features: ['budget', 'revenue', 'popularity', 'runtime', 'vote_average', 'vote_count']\n",
      "   Scaler saved to ../models/numerical_scaler.pkl\n",
      "   Creating derived features...\n",
      "   Numerical preprocessing complete\n"
     ]
    }
   ],
   "source": [
    "# Advanced numerical preprocessing\n",
    "print(\"Advanced Numerical Feature Processing:\")\n",
    "\n",
    "# Identify skewed numerical features for log transformation\n",
    "skewed_features = ['budget', 'revenue', 'popularity', 'runtime', 'vote_count']\n",
    "skewed_features = [col for col in skewed_features if col in df.columns]\n",
    "\n",
    "print(f\"   Applying log transformation to skewed features: {skewed_features}\")\n",
    "for col in skewed_features:\n",
    "    # Apply log1p transformation (handles zeros)\n",
    "    df[f'{col}_log'] = np.log1p(df[col])\n",
    "    \n",
    "    # Also create original scaled version\n",
    "    df[col] = df[col].apply(lambda x: np.log1p(x))\n",
    "\n",
    "# Standardize numerical features for hybrid model\n",
    "numerical_features = ['budget', 'revenue', 'popularity', 'runtime', 'vote_average', 'vote_count']\n",
    "numerical_features = [col for col in numerical_features if col in df.columns]\n",
    "\n",
    "if numerical_features:\n",
    "    print(f\"   Standardizing numerical features: {numerical_features}\")\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "    \n",
    "    # Save scaler for later use\n",
    "    import joblib\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    joblib.dump(scaler, '../models/numerical_scaler.pkl')\n",
    "    print(f\"   Scaler saved to ../models/numerical_scaler.pkl\")\n",
    "\n",
    "# Create additional derived features\n",
    "print(\"   Creating derived features...\")\n",
    "\n",
    "# Popularity tier (for filtering)\n",
    "if 'popularity' in df.columns:\n",
    "    df['popularity_tier'] = pd.qcut(df['popularity'], q=5, labels=['Low', 'Below_Avg', 'Average', 'Above_Avg', 'High'])\n",
    "\n",
    "# Rating tier\n",
    "if 'vote_average' in df.columns:\n",
    "    df['rating_tier'] = pd.cut(df['vote_average'], \n",
    "                              bins=[-np.inf, 4, 5.5, 7, 8.5, np.inf], \n",
    "                              labels=['Poor', 'Below_Avg', 'Good', 'Very_Good', 'Excellent'])\n",
    "\n",
    "print(f\"   Numerical preprocessing complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Quality Assessment:\n",
      "   Duplicate movies: 0\n",
      "   Movies with insufficient text features: 238\n",
      "   Outliers detected: budget: 283, revenue: 433, popularity: 33, runtime: 44, vote_average: 40, vote_count: 24\n",
      "\n",
      "Final Dataset Statistics:\n",
      "   Movies: 2723\n",
      "   Features: 62\n",
      "   Year range: 1927 - 2016\n",
      "   Average rating: -0.00\n",
      "   Unique genres: 19\n",
      "   Memory usage: 12.6 MB\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive data quality assessment\n",
    "print(\"Data Quality Assessment:\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated(subset=['original_title', 'release_year']).sum()\n",
    "print(f\"   Duplicate movies: {duplicates}\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"   Removing {duplicates} duplicates...\")\n",
    "    df = df.drop_duplicates(subset=['original_title', 'release_year'], keep='first')\n",
    "\n",
    "# Check text feature quality\n",
    "empty_text = (df['enhanced_text_features'].str.len() < 10).sum()\n",
    "print(f\"   Movies with insufficient text features: {empty_text}\")\n",
    "\n",
    "# Check for outliers in numerical features\n",
    "outlier_summary = []\n",
    "for col in numerical_features:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "        outlier_summary.append(f\"{col}: {outliers}\")\n",
    "\n",
    "print(f\"   Outliers detected: {', '.join(outlier_summary)}\")\n",
    "\n",
    "# Final dataset statistics\n",
    "print(f\"\\nFinal Dataset Statistics:\")\n",
    "print(f\"   Movies: {len(df)}\")\n",
    "print(f\"   Features: {len(df.columns)}\")\n",
    "print(f\"   Year range: {df['release_year'].min():.0f} - {df['release_year'].max():.0f}\")\n",
    "print(f\"   Average rating: {df['vote_average'].mean():.2f}\")\n",
    "print(f\"   Unique genres: {len(set([g for sublist in df['genres_list'] for g in sublist]))}\")\n",
    "print(f\"   Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Enhanced Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Enhanced Processed Dataset:\n",
      "   Enhanced dataset saved: ../data/processed/movies_enhanced_processed.csv\n",
      "   Backup saved: ../data/processed/movies_final_processed.csv\n",
      "   Feature summary saved: ../data/processed/feature_summary.json\n",
      "\n",
      "ENHANCED PREPROCESSING COMPLETE!\n",
      "Dataset ready for advanced LSA movie recommendation system\n",
      "\n",
      " Key Enhancements:\n",
      "   ✓ Weighted text features for better LSA performance\n",
      "   ✓ Advanced text cleaning and preprocessing\n",
      "   ✓ Comprehensive numerical feature engineering\n",
      "   ✓ Multiple text feature combinations\n",
      "   ✓ Quality assessment and outlier detection\n",
      "   ✓ Derived features for enhanced recommendations\n",
      "\n",
      "Sample Enhanced Features:\n",
      "   Movie: Avatar\n",
      "   Enhanced text (first 100 chars): 22nd century paraplegic marine dispatched moon pandora unique mission becomes torn following order p...\n",
      "   Genres: ['Action', 'Adventure', 'Fantasy', 'Science Fiction']\n",
      "   Rating tier: Poor\n",
      "   Popularity tier: High\n"
     ]
    }
   ],
   "source": [
    "# Save the enhanced processed dataset\n",
    "print(\"Saving Enhanced Processed Dataset:\")\n",
    "\n",
    "# Ensure processed folder exists\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "# Save main processed dataset\n",
    "output_path = '../data/processed/movies_enhanced_processed.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"   Enhanced dataset saved: {output_path}\")\n",
    "\n",
    "# Also save a backup of the original processed version\n",
    "backup_path = '../data/processed/movies_final_processed.csv'\n",
    "df.to_csv(backup_path, index=False)\n",
    "print(f\"   Backup saved: {backup_path}\")\n",
    "\n",
    "# Create a feature summary file\n",
    "feature_summary = {\n",
    "    'total_movies': len(df),\n",
    "    'total_features': len(df.columns),\n",
    "    'text_features': ['text_features', 'enhanced_text_features', 'genre_text'],\n",
    "    'numerical_features': numerical_features,\n",
    "    'list_features': ['genres_list', 'keywords_list', 'cast_list', 'director_list', 'key_crew_list'],\n",
    "    'derived_features': ['popularity_tier', 'rating_tier', 'weighted_rating', 'popularity_score'],\n",
    "    'preprocessing_applied': {\n",
    "        'text_cleaning': True,\n",
    "        'log_transformation': True,\n",
    "        'standardization': True,\n",
    "        'feature_weighting': True,\n",
    "        'duplicate_removal': True\n",
    "    }\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('../data/processed/feature_summary.json', 'w') as f:\n",
    "    json.dump(feature_summary, f, indent=2)\n",
    "\n",
    "print(f\"   Feature summary saved: ../data/processed/feature_summary.json\")\n",
    "\n",
    "print(\"\\nENHANCED PREPROCESSING COMPLETE!\")\n",
    "print(\"Dataset ready for advanced LSA movie recommendation system\")\n",
    "print(\"\\n Key Enhancements:\")\n",
    "print(\"   Weighted text features for better LSA performance\")\n",
    "print(\"   Advanced text cleaning and preprocessing\")\n",
    "print(\"   Comprehensive numerical feature engineering\")\n",
    "print(\"   Multiple text feature combinations\")\n",
    "print(\"   Quality assessment and outlier detection\")\n",
    "print(\"   Derived features for enhanced recommendations\")\n",
    "\n",
    "# Display sample of enhanced features\n",
    "print(\"\\nSample Enhanced Features:\")\n",
    "sample_movie = df.iloc[0]\n",
    "print(f\"   Movie: {sample_movie['original_title']}\")\n",
    "print(f\"   Enhanced text (first 100 chars): {sample_movie['enhanced_text_features'][:100]}...\")\n",
    "print(f\"   Genres: {sample_movie['genres_list']}\")\n",
    "print(f\"   Rating tier: {sample_movie.get('rating_tier', 'N/A')}\")\n",
    "print(f\"   Popularity tier: {sample_movie.get('popularity_tier', 'N/A')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
